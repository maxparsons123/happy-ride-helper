<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Taxi AI Voice Test</title>
  <style>
    * { box-sizing: border-box; }
    body { 
      font-family: -apple-system, sans-serif; 
      max-width: 700px; 
      margin: 40px auto; 
      padding: 20px;
      background: #1a1a2e;
      color: #eee;
    }
    h1 { color: #d4af37; margin-bottom: 8px; }
    .status { 
      padding: 8px 16px; 
      border-radius: 20px; 
      display: inline-block;
      margin-bottom: 20px;
      font-size: 14px;
    }
    .status.connected { background: #2e7d32; }
    .status.disconnected { background: #c62828; }
    .status.connecting { background: #f57c00; }
    #messages {
      background: #16213e;
      border-radius: 12px;
      padding: 16px;
      height: 350px;
      overflow-y: auto;
      margin-bottom: 16px;
    }
    .message {
      padding: 10px 14px;
      margin: 8px 0;
      border-radius: 12px;
      max-width: 85%;
    }
    .user { 
      background: #d4af37; 
      color: #1a1a2e;
      margin-left: auto;
      text-align: right;
    }
    .assistant { 
      background: #0f3460; 
      color: #eee;
    }
    .system { 
      background: #333; 
      color: #888;
      font-size: 12px;
      text-align: center;
      max-width: 100%;
    }
    .latency {
      font-size: 11px;
      color: #4caf50;
      margin-top: 4px;
    }
    .booking {
      background: #2e7d32;
      color: white;
      padding: 16px;
      border-radius: 12px;
      margin: 8px 0;
    }
    #inputArea {
      display: flex;
      gap: 8px;
      margin-bottom: 16px;
    }
    input {
      flex: 1;
      padding: 14px;
      border-radius: 25px;
      border: none;
      background: #16213e;
      color: #eee;
      font-size: 16px;
    }
    input:focus { outline: 2px solid #d4af37; }
    button {
      padding: 14px 24px;
      border-radius: 25px;
      border: none;
      background: #d4af37;
      color: #1a1a2e;
      font-weight: bold;
      cursor: pointer;
    }
    button:hover { background: #c9a227; }
    button:disabled { background: #555; cursor: not-allowed; }
    .controls { margin-bottom: 16px; display: flex; gap: 8px; flex-wrap: wrap; }
    .voice-btn {
      background: #e53935;
      color: white;
      font-size: 18px;
      width: 60px;
      height: 60px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .voice-btn.recording {
      background: #4caf50;
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.1); }
    }
    .voice-area {
      display: flex;
      align-items: center;
      gap: 16px;
      padding: 16px;
      background: #16213e;
      border-radius: 12px;
      margin-bottom: 16px;
    }
    .voice-status {
      flex: 1;
    }
    .metrics {
      background: #0f3460;
      border-radius: 12px;
      padding: 16px;
      margin-top: 16px;
    }
    .metrics h3 { margin: 0 0 12px 0; color: #d4af37; }
    .metric-row {
      display: flex;
      justify-content: space-between;
      padding: 8px 0;
      border-bottom: 1px solid #1a1a2e;
    }
    .metric-value { color: #4caf50; font-weight: bold; }
  </style>
</head>
<body>
  <h1>üöï Imtech Taxi Voice Test</h1>
  <div id="statusIndicator" class="status disconnected">Disconnected</div>
  
  <div class="controls">
    <button onclick="connect()">Connect</button>
    <button onclick="disconnect()">Disconnect</button>
  </div>

  <div class="voice-area">
    <button id="voiceBtn" class="voice-btn" onmousedown="startRecording()" onmouseup="stopRecording()" ontouchstart="startRecording()" ontouchend="stopRecording()" disabled>
      üé§
    </button>
    <div class="voice-status">
      <strong>Hold to speak</strong><br>
      <span id="voiceStatus">Connect first...</span>
    </div>
  </div>
  
  <div id="messages"></div>
  
  <div id="inputArea">
    <input type="text" id="userInput" placeholder="Or type a message..." onkeypress="if(event.key==='Enter')sendMessage()">
    <button onclick="sendMessage()">Send</button>
  </div>

  <div class="metrics">
    <h3>üìä Latency Metrics</h3>
    <div class="metric-row">
      <span>Last response time:</span>
      <span class="metric-value" id="lastLatency">--</span>
    </div>
    <div class="metric-row">
      <span>Average response:</span>
      <span class="metric-value" id="avgLatency">--</span>
    </div>
    <div class="metric-row">
      <span>First audio byte:</span>
      <span class="metric-value" id="firstAudioLatency">--</span>
    </div>
    <div class="metric-row">
      <span>Responses:</span>
      <span class="metric-value" id="responseCount">0</span>
    </div>
  </div>

  <script>
    const WS_URL = 'wss://xsdlzoyaosfbbwzmcinq.supabase.co/functions/v1/taxi-realtime';
    let ws = null;
    let currentTranscript = '';
    let audioContext = null;
    let mediaStream = null;
    let processor = null;
    let isRecording = false;
    
    // Latency tracking
    let speechStartTime = 0;
    let firstAudioTime = 0;
    let latencies = [];

    function setStatus(status) {
      const el = document.getElementById('statusIndicator');
      el.className = 'status ' + status;
      el.textContent = status.charAt(0).toUpperCase() + status.slice(1);
    }

    function addMessage(text, type, latency = null) {
      const messages = document.getElementById('messages');
      const div = document.createElement('div');
      div.className = 'message ' + type;
      div.innerHTML = text;
      if (latency) {
        div.innerHTML += `<div class="latency">‚ö° ${latency}ms</div>`;
      }
      messages.appendChild(div);
      messages.scrollTop = messages.scrollHeight;
    }

    function addBooking(booking) {
      const messages = document.getElementById('messages');
      const div = document.createElement('div');
      div.className = 'booking';
      div.innerHTML = `
        <strong>‚úÖ Booking Confirmed!</strong><br>
        üìç Pickup: ${booking.pickup}<br>
        üéØ Destination: ${booking.destination}<br>
        üë• Passengers: ${booking.passengers}<br>
        üí∑ Fare: ${booking.fare}<br>
        ‚è±Ô∏è ETA: ${booking.eta}
      `;
      messages.appendChild(div);
      messages.scrollTop = messages.scrollHeight;
    }

    function updateMetrics(latency) {
      latencies.push(latency);
      document.getElementById('lastLatency').textContent = latency + 'ms';
      document.getElementById('avgLatency').textContent = Math.round(latencies.reduce((a,b) => a+b, 0) / latencies.length) + 'ms';
      document.getElementById('responseCount').textContent = latencies.length;
    }

    // Audio playback
    let audioQueue = [];
    let isPlaying = false;

    async function playAudioChunk(base64Audio) {
      if (!audioContext) {
        audioContext = new AudioContext({ sampleRate: 24000 });
      }

      // Decode base64 to PCM
      const binaryString = atob(base64Audio);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      // Convert to Float32 (PCM16 to Float32)
      const int16 = new Int16Array(bytes.buffer);
      const float32 = new Float32Array(int16.length);
      for (let i = 0; i < int16.length; i++) {
        float32[i] = int16[i] / 32768;
      }

      audioQueue.push(float32);
      if (!isPlaying) playQueue();
    }

    async function playQueue() {
      if (audioQueue.length === 0) {
        isPlaying = false;
        return;
      }
      isPlaying = true;

      const samples = audioQueue.shift();
      const buffer = audioContext.createBuffer(1, samples.length, 24000);
      buffer.copyToChannel(samples, 0);

      const source = audioContext.createBufferSource();
      source.buffer = buffer;
      source.connect(audioContext.destination);
      source.onended = () => playQueue();
      source.start();
    }

    async function connect() {
      if (ws && ws.readyState === WebSocket.OPEN) {
        addMessage('Already connected', 'system');
        return;
      }

      setStatus('connecting');
      addMessage('Connecting to taxi AI...', 'system');

      // Initialize audio context
      audioContext = new AudioContext({ sampleRate: 24000 });

      ws = new WebSocket(WS_URL);

      ws.onopen = () => {
        setStatus('connected');
        addMessage('Connected! Hold mic button to speak.', 'system');
        document.getElementById('voiceBtn').disabled = false;
        document.getElementById('voiceStatus').textContent = 'Ready - hold to speak';
        
        ws.send(JSON.stringify({
          type: 'init',
          call_id: 'voice-test-' + Date.now()
        }));
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        console.log('Received:', data);

        // Track first audio latency
        if (data.type === 'audio' && speechStartTime > 0 && firstAudioTime === 0) {
          firstAudioTime = Date.now();
          const latency = firstAudioTime - speechStartTime;
          document.getElementById('firstAudioLatency').textContent = latency + 'ms';
          updateMetrics(latency);
        }

        if (data.type === 'audio') {
          playAudioChunk(data.audio);
        }

        if (data.type === 'transcript') {
          if (data.role === 'assistant') {
            currentTranscript += data.text;
          } else if (data.role === 'user') {
            addMessage(data.text, 'user');
          }
        }

        if (data.type === 'response_done' && currentTranscript) {
          const responseLatency = speechStartTime > 0 ? Date.now() - speechStartTime : null;
          addMessage(currentTranscript, 'assistant', responseLatency);
          currentTranscript = '';
          speechStartTime = 0;
          firstAudioTime = 0;
        }

        if (data.type === 'booking_confirmed') {
          addBooking(data.booking);
        }

        if (data.type === 'error') {
          addMessage('Error: ' + JSON.stringify(data.error), 'system');
        }
      };

      ws.onclose = () => {
        setStatus('disconnected');
        addMessage('Disconnected', 'system');
        document.getElementById('voiceBtn').disabled = true;
        document.getElementById('voiceStatus').textContent = 'Connect first...';
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
        addMessage('Connection error', 'system');
      };
    }

    function disconnect() {
      stopRecording();
      if (ws) {
        ws.close();
        ws = null;
      }
    }

    async function startRecording() {
      if (!ws || ws.readyState !== WebSocket.OPEN) return;
      if (isRecording) return;

      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 24000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          }
        });

        audioContext = new AudioContext({ sampleRate: 24000 });
        const source = audioContext.createMediaStreamSource(mediaStream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);

        processor.onaudioprocess = (e) => {
          if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;

          const inputData = e.inputBuffer.getChannelData(0);
          
          // Convert Float32 to PCM16
          const int16 = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }

          // Convert to base64
          const uint8 = new Uint8Array(int16.buffer);
          let binary = '';
          for (let i = 0; i < uint8.length; i++) {
            binary += String.fromCharCode(uint8[i]);
          }
          const base64 = btoa(binary);

          ws.send(JSON.stringify({
            type: 'audio',
            audio: base64
          }));
        };

        source.connect(processor);
        processor.connect(audioContext.destination);

        isRecording = true;
        speechStartTime = Date.now();
        firstAudioTime = 0;
        document.getElementById('voiceBtn').classList.add('recording');
        document.getElementById('voiceStatus').textContent = 'üî¥ Recording...';
        
      } catch (error) {
        console.error('Mic error:', error);
        addMessage('Microphone access denied', 'system');
      }
    }

    function stopRecording() {
      if (!isRecording) return;

      isRecording = false;
      document.getElementById('voiceBtn').classList.remove('recording');
      document.getElementById('voiceStatus').textContent = 'Processing...';

      if (processor) {
        processor.disconnect();
        processor = null;
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach(t => t.stop());
        mediaStream = null;
      }

      // VAD will auto-detect end of speech
      setTimeout(() => {
        if (ws && ws.readyState === WebSocket.OPEN) {
          document.getElementById('voiceStatus').textContent = 'Ready - hold to speak';
        }
      }, 500);
    }

    function sendMessage() {
      const input = document.getElementById('userInput');
      const text = input.value.trim();
      
      if (!text || !ws || ws.readyState !== WebSocket.OPEN) return;

      speechStartTime = Date.now();
      firstAudioTime = 0;

      ws.send(JSON.stringify({
        type: 'text',
        text: text
      }));

      addMessage(text, 'user');
      input.value = '';
    }
  </script>
</body>
</html>
