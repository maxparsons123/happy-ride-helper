using System;
using System.Collections.Concurrent;
using System.Net;
using SIPSorcery.Media;
using SIPSorcery.Net;
using SIPSorceryMedia.Abstractions;

namespace TaxiSipBridge;

/// <summary>
/// Direct RTP Playout for G.711 mode (8kHz passthrough).
/// Receives Œº-law from OpenAI and outputs directly to SIP.
/// 
/// Key Features:
/// - Direct Œº-law passthrough (no resampling when SIP uses PCMU)
/// - Direct Œº-law‚ÜíA-law transcode (no PCM intermediate when SIP uses PCMA)
/// - NAT punch-through via symmetric RTP
/// - Timer-driven 20ms cadence for stable delivery
/// - Grace period before OnQueueEmpty to prevent premature cutoff
/// </summary>
public class DirectRtpPlayoutG711 : IDisposable
{
    private const int FRAME_SIZE_BYTES = 160;  // 20ms @ 8kHz = 160 bytes G.711
    private const int FRAME_MS = 20;
    private const int MIN_FRAMES_TO_START = 5; // 100ms cushion
    private const int GRACE_PERIOD_FRAMES = 5; // 100ms grace before declaring done

    private readonly ConcurrentQueue<byte[]> _frameBuffer = new();
    private readonly VoIPMediaSession _mediaSession;
    private readonly byte[] _outputBuffer = new byte[FRAME_SIZE_BYTES];

    private System.Threading.Timer? _rtpTimer;
    private uint _timestamp = 0;
    private bool _isCurrentlySpeaking = false;
    private int _emptyFramesCount = 0;
    private int _framesSent = 0;

    // Codec configuration
    private bool _useALaw = false;
    private int _payloadType = 0; // 0 = PCMU, 8 = PCMA
    private byte _silenceByte = 0xFF; // Œº-law silence

    // NAT tracking
    private IPEndPoint? _lastRemoteEndpoint;

    // Stats
    private int _totalFramesQueued = 0;

    public event Action? OnQueueEmpty;
    public event Action<string>? OnLog;

    public int PendingFrameCount => _frameBuffer.Count;

    public DirectRtpPlayoutG711(VoIPMediaSession mediaSession)
    {
        _mediaSession = mediaSession ?? throw new ArgumentNullException(nameof(mediaSession));
        _mediaSession.AcceptRtpFromAny = true;
        _mediaSession.OnRtpPacketReceived += HandleSymmetricRtp;
    }

    /// <summary>
    /// Set the output codec (PCMU or PCMA).
    /// </summary>
    public void SetCodec(AudioCodecsEnum codec, int payloadType)
    {
        _useALaw = (codec == AudioCodecsEnum.PCMA);
        _payloadType = payloadType;
        _silenceByte = _useALaw ? (byte)0xD5 : (byte)0xFF;
        OnLog?.Invoke($"[DirectRtpG711] Codec set to {codec} (PT{payloadType})");
    }

    /// <summary>
    /// Symmetric RTP: Lock outbound audio to the actual caller endpoint (bypasses NAT issues).
    /// </summary>
    private void HandleSymmetricRtp(IPEndPoint remoteEndPoint, SDPMediaTypesEnum mediaType, RTPPacket rtpPacket)
    {
        if (mediaType == SDPMediaTypesEnum.audio)
        {
            if (_lastRemoteEndpoint == null || !_lastRemoteEndpoint.Equals(remoteEndPoint))
            {
                _lastRemoteEndpoint = remoteEndPoint;
                try
                {
                    _mediaSession.SetDestination(SDPMediaTypesEnum.audio, remoteEndPoint, remoteEndPoint);
                    OnLog?.Invoke($"[NAT] ‚úì RTP locked to {remoteEndPoint}");
                }
                catch (Exception ex)
                {
                    OnLog?.Invoke($"[NAT] ‚ö†Ô∏è SetDestination failed: {ex.Message}");
                }
            }
        }
    }

    /// <summary>
    /// Buffer a Œº-law frame from OpenAI (160 bytes = 20ms @ 8kHz).
    /// Frame is transcoded to A-law on output if carrier uses PCMA.
    /// </summary>
    public void BufferMuLawFrame(byte[] mulawFrame)
    {
        if (mulawFrame == null || mulawFrame.Length != FRAME_SIZE_BYTES) return;

        _frameBuffer.Enqueue(mulawFrame);
        _totalFramesQueued++;
    }

    /// <summary>
    /// Buffer multiple Œº-law frames at once.
    /// </summary>
    public void BufferMuLawFrames(IEnumerable<byte[]> frames)
    {
        foreach (var frame in frames)
            BufferMuLawFrame(frame);
    }

    /// <summary>
    /// Clear buffer and reset state (call on barge-in or new response).
    /// </summary>
    public void Clear()
    {
        while (_frameBuffer.TryDequeue(out _)) { }
        _isCurrentlySpeaking = false;
        _emptyFramesCount = 0;
    }

    public void Start()
    {
        _framesSent = 0;
        _rtpTimer = new System.Threading.Timer(SendFrame, null, 0, FRAME_MS);
        OnLog?.Invoke("[DirectRtpG711] Started");
    }

    public void Stop()
    {
        _rtpTimer?.Dispose();
        _rtpTimer = null;
        OnLog?.Invoke($"[DirectRtpG711] Stopped ({_framesSent} frames sent)");
    }

    private void SendFrame(object? state)
    {
        // Wait for minimum buffer before starting (absorbs OpenAI jitter)
        if (!_isCurrentlySpeaking)
        {
            if (_frameBuffer.Count < MIN_FRAMES_TO_START)
            {
                SendSilence();
                return;
            }
            _isCurrentlySpeaking = true;
            _emptyFramesCount = 0;
            OnLog?.Invoke($"[RTP] ‚ñ∂Ô∏è Playing ({_frameBuffer.Count * FRAME_SIZE_BYTES} samples buffered)");
        }

        if (_frameBuffer.TryDequeue(out var mulawFrame))
        {
            _emptyFramesCount = 0;
            
            // Transcode if needed and send
            if (_useALaw)
            {
                // Œº-law ‚Üí A-law direct transcode (no PCM intermediate)
                var alawFrame = AudioCodecs.TranscodeMuLawToALaw(mulawFrame);
                SendRtpFrame(alawFrame);
            }
            else
            {
                // Direct Œº-law passthrough
                SendRtpFrame(mulawFrame);
            }

            _framesSent++;
            if (_framesSent % 50 == 0)
                OnLog?.Invoke($"[RTP] üì§ Sent {_framesSent} frames ({_framesSent * FRAME_SIZE_BYTES} samples, queue: {_frameBuffer.Count * FRAME_SIZE_BYTES})");
        }
        else
        {
            _emptyFramesCount++;

            // Grace period: keep sending silence before declaring "done"
            if (_emptyFramesCount < GRACE_PERIOD_FRAMES)
            {
                SendSilence();
            }
            else
            {
                // Only NOW declare speaking complete
                if (_isCurrentlySpeaking)
                {
                    _isCurrentlySpeaking = false;
                    OnLog?.Invoke($"[RTP] ‚èπÔ∏è Finished ({_framesSent} frames sent, {_framesSent * FRAME_SIZE_BYTES} samples total)");
                    OnQueueEmpty?.Invoke();
                }
                SendSilence();
            }
        }
    }

    private void SendRtpFrame(byte[] frame)
    {
        try
        {
            _mediaSession.SendAudioRaw(frame, (int)_timestamp, 0, _payloadType);
            _timestamp += FRAME_SIZE_BYTES;
        }
        catch (Exception ex)
        {
            OnLog?.Invoke($"[RTP] ‚ö†Ô∏è SendAudioRaw error: {ex.Message}");
        }
    }

    private void SendSilence()
    {
        Array.Fill(_outputBuffer, _silenceByte);
        try
        {
            _mediaSession.SendAudioRaw(_outputBuffer, (int)_timestamp, 0, _payloadType);
            _timestamp += FRAME_SIZE_BYTES;
        }
        catch { }
    }

    public void Dispose()
    {
        _mediaSession.OnRtpPacketReceived -= HandleSymmetricRtp;
        Stop();
        Clear();
    }
}
